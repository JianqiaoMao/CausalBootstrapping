{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2525b009",
   "metadata": {},
   "source": [
    "# causalBootstrapping: Tutorial 03\n",
    "\n",
    "A series of tutorials demonstrating the use of the causalBootstrapping library.\n",
    "\n",
    "### General Causal Bootstrapping\n",
    "\n",
    "This tutorial mainly focuses on illustrating the use of causal bootstrapping interfaces for general causal graphs: `general_cb_analysis()` and `general_causal_bootstrapping_simple()` and `general_causal_bootstrapping_simu()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c12160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import causalBootstrapping as cb\n",
    "from distEst_lib import MultivarContiDistributionEstimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca098a",
   "metadata": {},
   "source": [
    "#### Usage example: general_cb_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44041537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a causal graph\n",
    "causal_graph = '\"General Causal Graph\"; \\\n",
    "                Y; X; U; Z; \\\n",
    "                U -> Y; \\\n",
    "                Y -> Z; \\\n",
    "                U -> Z; \\\n",
    "                Z -> X; \\\n",
    "                X <-> Y;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de276db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read demo data\n",
    "testdata_dir = \"../test_data/complex_scenario/\"\n",
    "X_train = pd.read_csv(testdata_dir + \"X_train.csv\")\n",
    "Y_train = pd.read_csv(testdata_dir + \"Y_train.csv\")\n",
    "Z_train = pd.read_csv(testdata_dir + \"Z_train.csv\")\n",
    "U_train = pd.read_csv(testdata_dir + \"U_train.csv\")\n",
    "# Re-formulate the data\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "Z_train = np.array(Z_train)\n",
    "U_train = np.array(U_train)\n",
    "data = {\"Y'\": Y_train,\n",
    "        \"X\": X_train,\n",
    "        \"Z\": Z_train,\n",
    "        \"U\": U_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4a6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interventional prob.:p_{Y}(X)=\\sum_{U,Y',Z}[p(X|U,Y',Z)p(Z|Y,U)p(U,Y')]\n",
      "Causal bootstrapping weights function: [P(U,Y')P(U,Y,Z)]/N*[P(U,Y',Z)P(U,Y)]\n",
      "Required distributions:\n",
      "1: P(U,Y')\n",
      "2: P(U,Y,Z)\n",
      "3: P(U,Y',Z)\n",
      "4: P(U,Y)\n"
     ]
    }
   ],
   "source": [
    "# Analyse the causal graph and give out the weights function expression and required distributions\n",
    "weight_func_lam, weight_func_str = cb.general_cb_analysis(causal_graph = causal_graph, \n",
    "                                                          effect_var_name = 'X', \n",
    "                                                          cause_var_name = 'Y',\n",
    "                                                          info_print = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4762854",
   "metadata": {},
   "source": [
    "#### Usage example: general_causal_bootstrapping_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25375f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the desired distributions\n",
    "n_bins_uyz = [0,0,0,0]\n",
    "n_bins_uy = [0,0]\n",
    "data_uyz = np.concatenate((U_train, Y_train, Z_train), axis = 1)\n",
    "data_uy = np.concatenate((U_train, Y_train), axis = 1)\n",
    "\n",
    "dist_estimator_uyz = MultivarContiDistributionEstimator(data_fit=data_uyz, n_bins = n_bins_uyz)\n",
    "pdf_uyz, puyz = dist_estimator_uyz.fit_histogram()\n",
    "dist_estimator_uy = MultivarContiDistributionEstimator(data_fit=data_uy, n_bins = n_bins_uy)\n",
    "pdf_uy, puy = dist_estimator_uy.fit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24bc0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the distribution mapping dict\n",
    "dist_map = {tuple(sorted([\"U\",\"Y\",\"Z\"])): lambda U, Y, Z: pdf_uyz([U, Y, Z]),\n",
    "            tuple(sorted([\"U\",\"Y'\",\"Z\"])): lambda U, Y_prime, Z: pdf_uyz([U, Y_prime, Z]),\n",
    "            tuple(sorted([\"U\",\"Y'\"])): lambda U, Y_prime: pdf_uy([U,Y_prime]),\n",
    "            tuple(sorted([\"U\",\"Y\"])): lambda U, Y: pdf_uy([U, Y])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b45e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap the dataset given the weight function expression\n",
    "cb_data = cb.general_causal_bootstrapping_simple(weight_func_lam = weight_func_lam, \n",
    "                                                 dist_map = dist_map, data = data, \n",
    "                                                 intv_var_name = \"Y\", kernel = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1462bbc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Compare the boostrapping results with the original dataset\n",
    "\n",
    "#confounding boundary\n",
    "conf_x2, conf_x3 = np.meshgrid(np.linspace(-6, 6, 20), np.linspace(-6, 6, 20))\n",
    "conf_x1 = np.zeros((20,20))\n",
    "# real boundary\n",
    "real_x1, real_x2 = np.meshgrid(np.linspace(-6, 6, 20), np.linspace(-6, 6, 20))\n",
    "real_x3 = np.full_like(real_x1, 0) \n",
    "\n",
    "# The original confounded dataset\n",
    "plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X_train[:,0],X_train[:,1],X_train[:,2],c=Y_train, s = 5, alpha = 0.5)\n",
    "surf1 = ax.plot_surface(conf_x1, conf_x2, conf_x3, alpha=0.5, rstride=100, cstride=100, color = \"yellow\", label = \"confounding boundary\")\n",
    "surf2 = ax.plot_surface(real_x1, real_x2, real_x3, alpha=0.5, rstride=100, cstride=100, color = \"green\", label = \"real boundary\")\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('X3')\n",
    "surf1._facecolors2d=surf1._facecolors\n",
    "surf1._edgecolors2d=surf1._edgecolors\n",
    "surf2._facecolors2d=surf2._facecolors\n",
    "surf2._edgecolors2d=surf2._edgecolors\n",
    "\n",
    "ax.legend()\n",
    "plt.title(\"Confounded dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# The bootstrapped de-confounded dataset\n",
    "plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(cb_data[\"X\"][:,0],cb_data[\"X\"][:,1],cb_data[\"X\"][:,2],c=cb_data[\"intv_Y\"], s = 5, alpha = 0.5)\n",
    "surf1 = ax.plot_surface(conf_x1, conf_x2, conf_x3, alpha=0.5, rstride=100, cstride=100, color = \"yellow\", label = \"confounding boundary\")\n",
    "surf2 = ax.plot_surface(real_x1, real_x2, real_x3, alpha=0.5, rstride=100, cstride=100, color = \"green\", label = \"real boundary\")\n",
    "surf1._facecolors2d=surf1._facecolors\n",
    "surf1._edgecolors2d=surf1._edgecolors\n",
    "surf2._facecolors2d=surf2._facecolors\n",
    "surf2._edgecolors2d=surf2._edgecolors\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('X3')\n",
    "ax.legend()\n",
    "plt.title(\"Deconfounded dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9e3042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.88      0.68       865\n",
      "           2       0.84      0.46      0.60      1135\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.70      0.67      0.64      2000\n",
      "weighted avg       0.72      0.65      0.63      2000\n",
      "\n",
      "Report of de-confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.84      0.72       865\n",
      "           2       0.83      0.62      0.71      1135\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.73      0.73      0.71      2000\n",
      "weighted avg       0.74      0.71      0.71      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train two linear support vector machines using confounded and de-confounded datasets\n",
    "clf_conf = svm.SVC(kernel = 'linear', C=2)\n",
    "clf_conf.fit(X_train, Y_train.reshape(-1))\n",
    "\n",
    "clf_cb = svm.SVC(kernel = 'linear', C=2)\n",
    "clf_cb.fit(cb_data['X'], cb_data[\"intv_Y\"].reshape(-1))\n",
    "\n",
    "## compare their performance on un-confounded test set\n",
    "X_test = pd.read_csv(testdata_dir +  \"X_test.csv\")\n",
    "Y_test = pd.read_csv(testdata_dir +  \"Y_test.csv\")\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "y_pred_conf = clf_conf.predict(X_test)\n",
    "print(\"Report of confonded model:\")\n",
    "print(classification_report(Y_test, y_pred_conf))\n",
    "\n",
    "y_pred_deconf = clf_cb.predict(X_test)\n",
    "print(\"Report of de-confonded model:\")\n",
    "print(classification_report(Y_test, y_pred_deconf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6b61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models' decision boundaries\n",
    "\n",
    "# confounded svm boundary\n",
    "xx1, xx2= np.meshgrid(np.linspace(-6, 6, 50), np.linspace(-6, 6, 50))\n",
    "xx_conf = (-clf_conf.intercept_[0] - clf_conf.coef_[0][0] * xx1 - clf_conf.coef_[0][1] * xx2) / clf_conf.coef_[0][2]\n",
    "\n",
    "# deconfounded svm boundary\n",
    "xx1, xx2= np.meshgrid(np.linspace(-6, 6, 50), np.linspace(-6, 6, 50))\n",
    "xx_cb = (-clf_cb.intercept_[0] - clf_cb.coef_[0][0] * xx1 - clf_cb.coef_[0][1] * xx2) / clf_cb.coef_[0][2]\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X_test[:,0],X_test[:,1],X_test[:,2],c=Y_test, s = 5, alpha = 0.5)\n",
    "surf1 = ax.plot_surface(conf_x1, conf_x2, conf_x3, alpha=0.5, rstride=100, cstride=100, color = \"yellow\", label = \"confounding boundary\")\n",
    "surf2 = ax.plot_surface(real_x1, real_x2, real_x3, alpha=0.5, rstride=100, cstride=100, color = \"green\", label = \"real boundary\")\n",
    "surf3 = ax.plot_surface(xx1, xx2, xx_conf, color='red', alpha=0.5, rstride=100, cstride=100, label = \"confounded decision boundary\")\n",
    "surf4 = ax.plot_surface(xx1, xx2, xx_cb, color='blue', alpha=0.5, rstride=100, cstride=100, label = \"confounded decision boundary\")\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('X3')\n",
    "surf1._facecolors2d=surf1._facecolors\n",
    "surf1._edgecolors2d=surf1._edgecolors\n",
    "surf2._facecolors2d=surf2._facecolors\n",
    "surf2._edgecolors2d=surf2._edgecolors\n",
    "surf3._facecolors2d=surf3._facecolors\n",
    "surf3._edgecolors2d=surf3._edgecolors\n",
    "surf4._facecolors2d=surf4._facecolors\n",
    "surf4._edgecolors2d=surf4._edgecolors\n",
    "ax.legend([\"Unconfounded test data\", \"confounding boundary\", \"real boundary\", \"confounded decision boundary\", \"deconfounded decision boundary\"])\n",
    "plt.title('Decision boundary comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351ee36",
   "metadata": {},
   "source": [
    "#### Usage example: general_causal_bootstrapping_simu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25dec646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set simulated interventions and bootstrap the data\n",
    "n_sample = 500\n",
    "N = Y_train.shape[0]\n",
    "cb_data_1= cb.general_causal_bootstrapping_simu(weight_func_lam = weight_func_lam, dist_map = dist_map, data = data, intv_var_value = {\"Y\": [1 for i in range(N)]}, n_sample = n_sample, kernel = None)\n",
    "cb_data_2= cb.general_causal_bootstrapping_simu(weight_func_lam = weight_func_lam, dist_map = dist_map, data = data, intv_var_value = {\"Y\": [2 for i in range(N)]}, n_sample = n_sample, kernel = None)\n",
    "cb_data = {}\n",
    "for key in cb_data_1:\n",
    "    cb_data[key] = np.vstack((cb_data_1[key], cb_data_2[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26d46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.88      0.68       865\n",
      "           2       0.84      0.46      0.60      1135\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.70      0.67      0.64      2000\n",
      "weighted avg       0.72      0.65      0.63      2000\n",
      "\n",
      "Report of de-confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76       865\n",
      "           2       0.83      0.78      0.80      1135\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.78      0.78      0.78      2000\n",
      "weighted avg       0.79      0.78      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train two linear support vector machines using confounded and de-confounded datasets\n",
    "clf_conf = svm.SVC(kernel = 'linear', C=2)\n",
    "clf_conf.fit(X_train, Y_train.reshape(-1))\n",
    "\n",
    "clf_cb = svm.SVC(kernel = 'linear', C=2)\n",
    "clf_cb.fit(cb_data['X'], cb_data[\"intv_Y\"].reshape(-1))\n",
    "\n",
    "## compare their performance on un-confounded test set\n",
    "X_test = pd.read_csv(testdata_dir +  \"X_test.csv\")\n",
    "Y_test = pd.read_csv(testdata_dir +  \"Y_test.csv\")\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "y_pred_conf = clf_conf.predict(X_test)\n",
    "print(\"Report of confonded model:\")\n",
    "print(classification_report(Y_test, y_pred_conf))\n",
    "\n",
    "y_pred_deconf = clf_cb.predict(X_test)\n",
    "print(\"Report of de-confonded model:\")\n",
    "print(classification_report(Y_test, y_pred_deconf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6cead4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models' decision boundaries\n",
    "# confounded svm boundary\n",
    "xx1, xx2= np.meshgrid(np.linspace(-6, 6, 50), np.linspace(-6, 6, 50))\n",
    "xx_conf = (-clf_conf.intercept_[0] - clf_conf.coef_[0][0] * xx1 - clf_conf.coef_[0][1] * xx2) / clf_conf.coef_[0][2]\n",
    "\n",
    "# deconfounded svm boundary\n",
    "xx1, xx2= np.meshgrid(np.linspace(-6, 6, 50), np.linspace(-6, 6, 50))\n",
    "xx_cb = (-clf_cb.intercept_[0] - clf_cb.coef_[0][0] * xx1 - clf_cb.coef_[0][1] * xx2) / clf_cb.coef_[0][2]\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X_test[:,0],X_test[:,1],X_test[:,2],c=Y_test, s = 5, alpha = 0.5)\n",
    "surf1 = ax.plot_surface(conf_x1, conf_x2, conf_x3, alpha=0.5, rstride=100, cstride=100, color = \"yellow\", label = \"confounding boundary\")\n",
    "surf2 = ax.plot_surface(real_x1, real_x2, real_x3, alpha=0.5, rstride=100, cstride=100, color = \"green\", label = \"real boundary\")\n",
    "surf3 = ax.plot_surface(xx1, xx2, xx_conf, color='red', alpha=0.5, rstride=100, cstride=100, label = \"confounded decision boundary\")\n",
    "surf4 = ax.plot_surface(xx1, xx2, xx_cb, color='blue', alpha=0.5, rstride=100, cstride=100, label = \"confounded decision boundary\")\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('X3')\n",
    "surf1._facecolors2d=surf1._facecolors\n",
    "surf1._edgecolors2d=surf1._edgecolors\n",
    "surf2._facecolors2d=surf2._facecolors\n",
    "surf2._edgecolors2d=surf2._edgecolors\n",
    "surf3._facecolors2d=surf3._facecolors\n",
    "surf3._edgecolors2d=surf3._edgecolors\n",
    "surf4._facecolors2d=surf4._facecolors\n",
    "surf4._edgecolors2d=surf4._edgecolors\n",
    "ax.legend([\"Unconfounded test data\", \"confounding boundary\", \"real boundary\", \"confounded decision boundary\", \"deconfounded decision boundary\"])\n",
    "plt.title('Decision boundary comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
